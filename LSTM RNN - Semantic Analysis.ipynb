{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading word vectors\n",
    "words = np.load('wordsList.npy')\n",
    "words = words.tolist() #Originally loaded as numpy array\n",
    "words = [word.decode('UTF-8') for word in words] #Encode words as UTF-8\n",
    "word_vectors = np.load('wordVectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.36540008e+00,   1.33039999e+00,  -5.22069991e-01,\n",
       "         9.64690030e-01,  -8.49120039e-03,  -7.19780028e-01,\n",
       "        -1.08099997e+00,   2.04430008e-03,  -8.93989980e-01,\n",
       "        -2.60939986e-01,   6.15069985e-01,  -2.86000013e-01,\n",
       "        -9.25300002e-01,   1.37659997e-01,   9.63559985e-01,\n",
       "         9.45629999e-02,   1.89659998e-01,   1.31579995e+00,\n",
       "        -1.20379996e+00,  -1.15590002e-02,  -1.15310001e+00,\n",
       "         2.84130007e-01,  -9.76380035e-02,   3.80719990e-01,\n",
       "        -6.82439983e-01,  -1.31830001e+00,  -4.31840003e-01,\n",
       "        -1.56760007e-01,  -2.56379992e-01,  -1.03460002e+00,\n",
       "         1.89440000e+00,   1.21389997e+00,  -9.61180031e-02,\n",
       "        -9.00200009e-01,   4.26369995e-01,   8.43020022e-01,\n",
       "        -1.51069999e-01,   4.67790008e-01,   9.30479988e-02,\n",
       "        -5.97299993e-01,  -7.08199978e-01,  -3.94320011e-01,\n",
       "        -2.78549999e-01,   6.45139992e-01,  -1.38630003e-01,\n",
       "         3.29470009e-01,   3.99260014e-01,   3.67320001e-01,\n",
       "        -7.08760023e-01,  -1.32200003e-01], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of word vector\n",
    "word_index = words.index(\"basketball\")\n",
    "word_vectors[word_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10326</td>\n",
       "      <td>The room was kind of clean but had a VERY stro...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10327</td>\n",
       "      <td>I stayed at the Crown Plaza April -- - April -...</td>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10328</td>\n",
       "      <td>I booked this hotel through Hotwire at the low...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10329</td>\n",
       "      <td>Stayed here with husband and sons on the way t...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10330</td>\n",
       "      <td>My girlfriends and I stayed here to celebrate ...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0  id10326  The room was kind of clean but had a VERY stro...   \n",
       "1  id10327  I stayed at the Crown Plaza April -- - April -...   \n",
       "2  id10328  I booked this hotel through Hotwire at the low...   \n",
       "3  id10329  Stayed here with husband and sons on the way t...   \n",
       "4  id10330  My girlfriends and I stayed here to celebrate ...   \n",
       "\n",
       "        Browser_Used Device_Used Is_Response  \n",
       "0               Edge      Mobile   not happy  \n",
       "1  Internet Explorer      Mobile   not happy  \n",
       "2            Mozilla      Tablet   not happy  \n",
       "3   InternetExplorer     Desktop       happy  \n",
       "4               Edge      Tablet   not happy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode the labels\n",
    "# Y_train.loc[data['Is_Response'].str.contains('not happy')] = 0\n",
    "# Y_train.loc[data['Is_Response'] == 'happy'] = 1\n",
    "m = len(data['Is_Response']) # number of examples\n",
    "Y_train = pd.get_dummies(data['Is_Response']) # [1,0] is not happy and [0,1] is happy\n",
    "Y_train = Y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = data['Description']\n",
    "#cleaning the comments data\n",
    "remove_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "X_train = X_data.apply(lambda comment: re.sub(remove_special_chars, \"\", comment.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     46\n",
       "1    202\n",
       "2    228\n",
       "3     93\n",
       "4    286\n",
       "Name: Description, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count average number of words\n",
    "# to obtain sequence length\n",
    "words_count = X_train.str.split().str.len() # get number of words per each comment\n",
    "words_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    38932.000000\n",
       "mean       154.069557\n",
       "std        128.114708\n",
       "min          4.000000\n",
       "25%         72.000000\n",
       "50%        120.000000\n",
       "75%        195.000000\n",
       "max       2275.000000\n",
       "Name: Description, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_length = 250 # 250 is reasonable decision as 75% of the data has length <= 195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = len(X_train) # number of examples\n",
    "uknown_vector_index = 399999\n",
    "X_train_int = np.zeros((m, seq_length), dtype='int32')\n",
    "# # Integerize the comments\n",
    "# for i in range(m):\n",
    "#     comment = X_train[0].split(\" \")\n",
    "#     word_counter = 0\n",
    "#     for word in comment:\n",
    "#         try:\n",
    "#             X_train_int[i][word_counter] = words.index(word)\n",
    "#         except ValueError:\n",
    "#             X_train_int[i][word_counter] = uknown_vector_index\n",
    "        \n",
    "#         word_counter += 1\n",
    "        \n",
    "#         if (word_counter == seq_length):\n",
    "#             break\n",
    "# np.save('integerized_comments', X_train_int) # save them the integerized comments\n",
    "# instead of computing the integerized_comments, they can be load\n",
    "X_train_int = np.load('integerized_comments.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to model.ckpt-100\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "batch_size = 1216\n",
    "num_batches = 32\n",
    "num_lstm_units = 64\n",
    "num_classes = 2\n",
    "iterations = 100000\n",
    "word_vec_dimensions = 50 # the loaded word2vec has 50 dimensions\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "Y = tf.placeholder(tf.float32, [batch_size, num_classes]) # labels\n",
    "X = tf.placeholder(tf.int32, [batch_size, seq_length]) # input_data\n",
    "\n",
    "data = tf.Variable(tf.zeros([batch_size, seq_length, word_vec_dimensions]), dtype=tf.float32)\n",
    "data = tf.nn.embedding_lookup(word_vectors, X)\n",
    "\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_lstm_units)\n",
    "lstm_cell = tf.contrib.rnn.DropoutWrapper(cell=lstm_cell, output_keep_prob=0.75)\n",
    "value, _ = tf.nn.dynamic_rnn(lstm_cell, data, dtype=tf.float32)\n",
    "\n",
    "weight = tf.Variable(tf.truncated_normal([num_lstm_units, num_classes]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[num_classes]))\n",
    "\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last_layer = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = tf.add((tf.matmul(last_layer, weight)), bias)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# supervisizing the training\n",
    "tf.summary.scalar('Loss', cost)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "\n",
    "minibatches = split_batches(X_train_int, Y_train, num_batches)\n",
    "for i in range(iterations):\n",
    "    #Next Batch of reviews\n",
    "    for minibatch in minibatches:\n",
    "        X_minibatch, Y_minibatch = minibatch\n",
    "        _ , minibatch_cost = sess.run([optimizer, cost], {X: X_minibatch, Y: Y_minibatch})\n",
    "        \n",
    "    #Save the network every 100 training iterations\n",
    "    if (i % 100 == 0 and i != 0):\n",
    "        save_path = saver.save(sess, \"model.ckpt\", global_step=i)\n",
    "        print(\"saved to %s\" % save_path)\n",
    "    #Write summary to Tensorboard\n",
    "    summary = sess.run(merged, {X: X_minibatch, Y: Y_minibatch})\n",
    "    writer.add_summary(summary, i)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_batches(X, Y, num_batches):\n",
    "    total_num_examples = len(X)\n",
    "    num_examples_per_batch = total_num_examples // num_batches\n",
    "    d = num_examples_per_batch\n",
    "    num_remainder_examples_last_batch = num_examples_per_batch - num_examples_per_batch * num_batches\n",
    "    minibatches = []\n",
    "    for x in range(0, num_batches):\n",
    "        minibatches.append((X[x*d:(x+1)*d, :], Y[x*d:(x+1)*d, :]))\n",
    "#     minibatches.append((X[x*num_batches: x*num_batches + num_remainder_examples_last_batch], \n",
    "#                         Y[x*num_batches: x*num_batches + num_remainder_examples_last_batch]\n",
    "#                        ))\n",
    "    return minibatches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1503px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
